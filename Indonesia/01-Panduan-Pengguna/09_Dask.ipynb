{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| <h1><b>Pemrosesan Paralel dengan Dask</b></h1> |  ![](files/piksel-logo-small.png) |\n",
    "|:---------|----------:|\n",
    "\n",
    "* **Prasyarat**: Pengguna notebook ini harus memiliki pemahaman dasar tentang:\n",
    "  * Cara menjalankan [Jupyter notebook](02_Jupyter_notebook.ipynb)\n",
    "  * Memeriksa produk dan pengukuran yang tersedia di [Piksel Products and measurement](03_Product_dan_measurement.ipynb)\n",
    "  * Cara [membuka data Piksel](04_Membuka_data.ipynb)\n",
    "  * Cara [plotting data](05_Plotting.ipynb)\n",
    "  * Cara menjalankan [Analisis dasar](06_Analisis_dasar.ipynb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Kata Kunci**: `index:panduan pemula`; `pemrosesan paralel`, `index:pemrosesan paralel`; `dask`, `index:pemrosesan paralel`; `panduan pemula`, `index:data yang digunakan`; `landsat 8 geomedian`, `index:paket python`; `dask`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîô Pendahuluan\n",
    "[Dask](https://dask.org/) adalah alat yang berguna saat bekerja dengan analisis skala besar (baik dalam ruang maupun waktu) karena membagi data menjadi bagian-bagian yang dapat dikelola dengan mudah dalam memori.\n",
    "Dask juga dapat menggunakan beberapa inti pemrosesan untuk mempercepat perhitungan.\n",
    "Hal ini memberikan banyak manfaat bagi analisis, yang akan dibahas dalam notebook ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notebook ini membahas cara mengaktifkan Dask sebagai bagian dari proses pemuatan data, yang memungkinkan analisis area yang lebih luas dan rentang waktu yang lebih panjang tanpa menyebabkan lingkungan Piksel mengalami crash, serta berpotensi mempercepat perhitungan.\n",
    "\n",
    "Topik yang dibahas dalam notebook ini meliputi:\n",
    "\n",
    "1. Perbedaan antara perintah pemuatan standar dan pemuatan dengan Dask.\n",
    "2. Mengaktifkan Dask dan Dask Dashboard.\n",
    "3. Menentukan ukuran chunk untuk pemuatan data.\n",
    "4. Memuat data dengan Dask.\n",
    "5. Menggabungkan operasi sebelum memuat data dan memahami grafik tugas (task graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÇÔ∏è‚Äç‚û°Ô∏è Memulai\n",
    "Untuk menjalankan pengenalan Dask ini, jalankan semua sel dalam notebook mulai dari sel \"Load packages\". Untuk bantuan dalam menjalankan sel notebook, lihat kembali notebook [Jupyter notebook](02_Jupyter_notebooks.ipynb) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Memuat Paket\n",
    "Sel di bawah ini mengimpor paket `datacube`, yang sudah menyertakan fungsi Dask.\n",
    "Paket `dea_tools` menyediakan akses ke fungsi pendukung yang berguna dalam modul `dask`, khususnya fungsi `create_local_dask_cluster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "\n",
    "from dea_tools.dask import create_local_dask_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Terhubung ke Datacube\n",
    "Langkah berikutnya adalah menghubungkan ke database datacube.\n",
    "Objek `dc` yang dihasilkan kemudian dapat digunakan untuk memuat data.\n",
    "Parameter `app` adalah nama unik yang digunakan untuk mengidentifikasi notebook, tetapi tidak berpengaruh pada analisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"08_parallel_processing_with_dask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öíÔ∏è Pemrosesan Standar\n",
    "Secara default, pustaka `datacube` **tidak** akan menggunakan Dask saat memuat data.\n",
    "Artinya, ketika `dc.load()` digunakan, semua data yang terkait dengan kueri pemuatan akan diminta dan dimuat ke dalam memori.\n",
    "\n",
    "Untuk area yang sangat luas atau rentang waktu yang panjang, hal ini dapat menyebabkan Jupyter Notebook mengalami crash.\n",
    "\n",
    "Untuk informasi lebih lanjut tentang cara menggunakan `dc.load()`, lihat notebook [Membuka Data](http://43.218.254.133:8888/notebooks/panduan-pengguna/03_Membuka_data.ipynb) dari Piksel.\n",
    "Di bawah ini, kami menunjukkan contoh pemuatan data standar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dc.load(\n",
    "    product=\"s2_l2a\",\n",
    "    measurements=['red', 'green', 'blue'],\n",
    "    output_crs=\"EPSG:32748\",\n",
    "    resolution=10,\n",
    "    time=('2023-01-01', '2023-01-10'),\n",
    "    longitude=(107.0, 107.1),\n",
    "    latitude=(-6.6, -6.5),\n",
    "    dask_chunks={\"time\": 1, \"x\": 512, \"y\": 512},\n",
    "    group_by=\"solar_day\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîõ Mengaktifkan Dask\n",
    "Salah satu fitur utama Dask adalah kemampuannya memanfaatkan beberapa inti CPU untuk mempercepat perhitungan, yang dikenal sebagai komputasi terdistribusi.\n",
    "Hal ini sangat berguna dalam situasi di mana Anda perlu melakukan banyak perhitungan pada kumpulan data yang besar.\n",
    "\n",
    "Untuk mengatur komputasi terdistribusi dengan Dask, langkah pertama adalah mengatur klien Dask menggunakan fungsi berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Sebuah tampilan output akan muncul, menampilkan informasi tentang `Client` dan `Cluster`.\n",
    "Untuk saat ini, yang paling penting adalah tautan setelah bagian **Dashboard**: yang terlihat seperti [/user/<email>/proxy/8787/status](#), di mana [\\<email\\>](#) adalah email Anda untuk Piksel.\n",
    "\n",
    "Tautan ini memungkinkan Anda untuk melihat bagaimana perhitungan yang sedang dijalankan berkembang. Ada dua cara untuk melihat dasbor ini:\n",
    "\n",
    "1. Klik tautan tersebut, yang akan membuka tab baru di browser Anda.\n",
    "2. Mengatur dasbor di dalam lingkungan Piksel.\n",
    "   \n",
    "Selanjutnya, kita akan membahas cara melakukan opsi kedua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Dashboard Dask di Piksel ###\n",
    "Pada menu bar di sebelah kiri, klik ikon Dask, seperti yang ditunjukkan di bawah ini:\n",
    "\n",
    "![Image](files/dask_icon.png)\n",
    "\n",
    "Salin dan tempel tautan **Dashboard** dari hasil print out Client ke dalam kotak teks DASK DASHBOARD URL:\n",
    "\n",
    "![Image](files/dask_daskboard.png)\n",
    "\n",
    "Jika URL valid, tombol-tombolnya akan berubah dari abu-abu menjadi oranye.\n",
    "Klik tombol **PROGRESS** yang berwarna oranye di panel Dask, yang akan membuka tab baru di dalam Lingkungan Piksel.\n",
    "\n",
    "Untuk melihat jendela Dask dan notebook aktif Anda pada waktu yang bersamaan, seret tab Progress Dask baru ke bagian bawah layar.\n",
    "\n",
    "Sekarang, ketika Anda melakukan komputasi dengan Dask, Anda akan melihat kemajuan komputasi ini di jendela Dask baru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Lazy Load\n",
    "Saat menggunakan Dask, fungsi `dc.load()` akan beralih dari memuat data secara langsung ke \"lazy-loading\" data.\n",
    "Ini berarti data hanya akan dimuat saat diperlukan untuk perhitungan, yang dapat menghemat waktu dan memori.\n",
    "\n",
    "Lazy-loading mengubah struktur data yang dikembalikan dari perintah `dc.load()`: `xarray.Dataset` yang dikembalikan akan terdiri dari objek `dask.array`.\n",
    "\n",
    "Untuk meminta data yang dimuat secara tunda, tambahkan parameter `dask_chunks` ke pemanggilan `dc.load()` Anda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_data = dc.load(\n",
    "    product=\"s2_l2a\",\n",
    "    measurements=['red', 'green', 'blue'],\n",
    "    output_crs=\"EPSG:32748\",\n",
    "    resolution=10,\n",
    "    time=('2023-01-01', '2023-01-10'),\n",
    "    longitude=(107.0, 107.1),\n",
    "    latitude=(-6.6, -6.5),\n",
    "    dask_chunks={\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "    group_by=\"solar_day\"   \n",
    ")\n",
    "lazy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Fungsi ini seharusnya mengembalikan hasil jauh lebih cepat, karena tidak ada data yang dibaca dari disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Chunks\n",
    "Setelah menambahkan parameter `dask_chunks` ke dalam `dc.load()`, data yang di-lazy-loaded akan berisi objek `dask.array` dengan `chunksize` yang terdaftar. `chunksize` ini harus sesuai dengan parameter `dask_chunks` yang diberikan sebelumnya pada pemanggilan `dc.load()`.\n",
    "\n",
    "Dask bekerja dengan membagi dataset besar menjadi potongan-potongan (chunks), yang dapat dibaca secara individual. Anda dapat menentukan jumlah piksel dalam setiap chunk untuk setiap dimensi dataset.\n",
    "\n",
    "Sebagai contoh, kami mengirimkan definisi chunk berikut ke dalam `dc.load()`:\n",
    "```\n",
    "dask_chunks = {'time': 1, 'x': 3000, 'y': 3000}\n",
    "```\n",
    "\n",
    "Definisi ini memberi tahu Dask untuk memotong data menjadi chunk yang berisi 3000 piksel dalam dimensi `x` dan `y`, serta satu ukuran pengukuran dalam dimensi time. Untuk itu, kami selalu mengatur `'time': 1` dalam definisi `dask_chunk`, karena file data hanya mencakup satu waktu pengukuran.\n",
    "\n",
    "Jika ukuran chunk tidak diberikan untuk dimensi tertentu, atau jika diatur ke -1, maka chunk tersebut akan disesuaikan dengan ukuran array pada dimensi tersebut. Ini berarti semua data pada dimensi tersebut akan dimuat sekaligus, bukannya dibagi menjadi chunk yang lebih kecil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Melihat Dask Chunks\n",
    "Untuk memahami secara visual bagaimana data telah dibagi menjadi chunks, kita dapat menggunakan atribut `.data` yang disediakan oleh `xarray`.\n",
    "\n",
    "Atribut ini dapat diterapkan pada setiap pengukuran dari data yang di-lazy-loaded. Ketika digunakan dalam Jupyter Notebook, atribut ini akan menampilkan tabel yang merangkum ukuran masing-masing chunk serta jumlah total chunk yang diperlukan.\n",
    "\n",
    "Contoh di bawah ini menggunakan pengukuran `red` dari data yang di-lazy-loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_data.red.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Dari kolom Chunk pada tabel, kita dapat melihat bahwa data telah dibagi menjadi 4 bagian (chunk), di mana setiap chunk memiliki bentuk `(1 waktu, 3000 piksel, 3000 piksel)` dan membutuhkan memori sebesar 18,00MB.\n",
    "\n",
    "Jika dibandingkan dengan kolom Array, penggunaan Dask memungkinkan kita untuk memuat 4 bagian data masing-masing sebesar 18,00MB, daripada harus langsung memuat satu bagian besar sebesar 57,67MB.\n",
    "\n",
    "Pendekatan ini sangat berguna saat bekerja dengan area yang luas atau rentang waktu yang panjang, karena seluruh array mungkin tidak selalu cukup untuk dimuat ke dalam memori yang tersedia. Dengan membagi dataset besar menjadi beberapa chunk dan memuatnya satu per satu, kita dapat melakukan perhitungan pada dataset besar tanpa menyebabkan sistem Piksel mengalami crash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Saat bekerja dengan data yang di-lazy-loaded, Anda harus secara spesifik meminta Dask untuk membaca dan memuat data ketika ingin menggunakannya.\n",
    "Sampai Anda melakukan ini, dataset yang di-lazy-loaded hanya mengetahui lokasi data, tetapi tidak mengetahui nilainya.\n",
    "\n",
    "Untuk memuat data dari disk, gunakan metode `.load()` pada `DataArray` atau `Dataset`.\n",
    "Jika Anda sudah membuka jendela progres Dask, Anda akan melihat proses komputasi berjalan di sana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "#Atur scheduler ke \"threads\" (dijalankan dalam proses yang sama, tidak memerlukan serialisasi)\n",
    "dask.config.set(scheduler='threads')\n",
    "loaded_data = lazy_data.load()\n",
    "loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Array Dask yang dibuat melalui lazy load\n",
    "```\n",
    "red      (time, y, x) uint16 dask.array<chunksize=(1, 3000, 3000), meta=np.ndarray>\n",
    "```\n",
    "\n",
    "sekarang telah digantikan dengan angka sebenarnya:\n",
    "\n",
    "```\n",
    " red      (time, y, x) uint16 1958 1940 1966 ... 4320 4348 4336\n",
    " ```\n",
    "\n",
    "\n",
    "\n",
    "Setelah menerapkan perintah `.load()`, data yang di-lazy-loaded menjadi sama dengan data yang dimuat dari query pertama.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Lazy operations\n",
    "\n",
    "Selain membagi data menjadi potongan-potongan kecil agar muat di memori, Dask memiliki keunggulan lain, yaitu dapat melacak bagaimana Anda ingin bekerja dengan data dan hanya menjalankan operasi yang diperlukan nanti.\n",
    "\n",
    "Sekarang, kita akan mengeksplorasi cara kerja ini dengan menghitung Normalized Difference Vegetation Index (NDVI) dari data kita.\n",
    "Untuk itu, kita akan melakukan lazy load lagi, kali ini dengan menambahkan pita near-infrared (`NIR`) ke dalam perintah `dc.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_data = dc.load(\n",
    "    product=\"s2_l2a\",\n",
    "    measurements=['red', 'green', 'blue','nir'],\n",
    "    output_crs=\"EPSG:32748\",\n",
    "    resolution=10,\n",
    "    time=('2023-01-01', '2023-01-10'),\n",
    "    longitude=(107.0, 107.1),\n",
    "    latitude=(-6.6, -6.5),\n",
    "    dask_chunks={\"time\": 1, \"x\": 3000, \"y\": 3000},\n",
    "    group_by=\"solar_day\"   \n",
    ")\n",
    "lazy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Menambahkan Lebih Banyak Tugas\n",
    "Keunggulan utama metode ini adalah kemampuannya untuk merangkai tugas-tugas sebelum memuat data.\n",
    "Dengan cara ini, Dask hanya akan memuat data yang benar-benar dibutuhkan untuk operasi akhir dalam rantai tugas tersebut.\n",
    "\n",
    "Kita bisa mendemonstrasikan ini dengan meminta hanya sebagian kecil dari red band.\n",
    "Jika kita melakukan ini pada data yang dimuat secara lazy, kita bisa melihat grafik tugas (task graph) yang baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_from_red = lazy_data.red[:, 100:200, 100:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Perhatikan bahwa tugas baru `getitem` telah ditambahkan, dan hanya berlaku pada chunk paling kiri.\n",
    "Jika kita memanggil `.load()` pada array Dask `extract_from_red`, Dask akan melacak operasi kembali melalui grafik tugas untuk menemukan hanya data yang relevan.\n",
    "\n",
    "Pendekatan ini dapat menghemat memori dan waktu secara signifikan.\n",
    "\n",
    "Kita bisa memastikan bahwa operasi di atas menghasilkan hasil yang sama seperti memuat data tanpa Dask dan melakukan subset secara manual dengan menjalankan perintah berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_red_subset = extract_from_red.load()\n",
    "data_red_subset = data.red[:, 100:200, 100:200]\n",
    "\n",
    "print(f\"The loaded arrays match: {lazy_red_subset.equals(data_red_subset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Karena array yang dihasilkan sama, maka lebih baik menggunakan lazy-loading untuk merangkai operasi bersama sebelum akhirnya memanggil `.load()`.\n",
    "\n",
    "Pendekatan ini menghemat waktu dan memori, karena Dask hanya akan memuat data input yang benar-benar diperlukan untuk mendapatkan output akhir.\n",
    "\n",
    "Dalam contoh ini, lazy-load hanya perlu memuat sebagian kecil dari band red, sedangkan metode pemuatan `data` biasa harus memuat seluruh band `red`, `green`, dan `blue` terlebih dahulu, lalu melakukan subset pada band red.\n",
    "Akibatnya, waktu dan memori terbuang untuk memuat data yang sebenarnya tidak digunakan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Keunggulan utama dari lazy-loading dalam Dask adalah kemampuannya untuk merangkai banyak operasi bersama sebelum akhirnya memuat hasil akhir.\n",
    "\n",
    "Di sini, kita akan merangkai beberapa langkah sekaligus untuk menghitung sebuah band baru dalam array kita, yaitu Normalized Difference Vegetation Index (NDVI).\n",
    "NDVI dihitung menggunakan band `red` dan `nir`, dengan rumus berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_diff = lazy_data.nir - lazy_data.red\n",
    "band_sum = lazy_data.nir + lazy_data.red\n",
    "\n",
    "lazy_data['ndvi'] = band_diff / band_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Dengan melakukan ini, array Dask `ndvi` yang baru ditambahkan ke dalam dataset `lazy_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Terakhir, kita dapat menghitung nilai NDVI dengan memanggil perintah `.load()`.\n",
    "Kita akan menyimpan hasilnya dalam variabel `ndvi_load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_load = lazy_data.ndvi.load()\n",
    "ndvi_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that running the `.load()` command also modifies the `ndvi` entry in the `lazy_load` dataset:\n",
    "\n",
    "Perhatikan bahwa menjalankan perintah `.load()` juga memodifikasi entri `ndvi` dalam dataset `lazy_load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Kamu bisa melihat bahwa `ndvi` adalah sebuah angka, sedangkan semua variabel lainnya merupakan array Dask.\n",
    "\n",
    "\n",
    "\n",
    "### Menjaga variabel tetap sebagai array Dask\n",
    "Jika Anda ingin menghitung nilai NDVI tetapi tetap membiarkan `ndvi` sebagai array Dask dalam `lazy_load`, Anda dapat menggunakan perintah `.compute()`.\n",
    "\n",
    "Untuk mendemonstrasikannya, pertama-tama kita mendefinisikan ulang variabel `ndvi` agar kembali menjadi array Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_data['ndvi'] = band_diff / band_sum\n",
    "lazy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sekarang, kita melakukan langkah yang sama seperti sebelumnya untuk menghitung NDVI, tetapi menggunakan `.compute()` alih-alih `.load()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_compute = lazy_data.ndvi.compute()\n",
    "ndvi_compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Anda dapat melihat bahwa nilai telah dihitung, tetapi seperti yang ditunjukkan di bawah ini, variabel `ndvi` tetap sebagai array Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Menggunakan `.compute()` memungkinkan Anda menghitung langkah-langkah perantara dan menyimpan hasilnya tanpa mengubah dataset atau array Dask asli. Namun, berhati-hatilah saat menggunakannya, karena dapat menyebabkan kebingungan tentang apa yang telah dan belum dimodifikasi, serta kemungkinan komputasi ulang untuk kuantitas yang sama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  üìö Bacaan Lebih Lanjut\n",
    "\n",
    "Untuk bacaan lebih lanjut tentang cara kerja Dask dan bagaimana Dask digunakan oleh xarray, silakan lihat sumber-sumber berikut:\n",
    "\n",
    " * http://xarray.pydata.org/en/stable/dask.html\n",
    " * https://dask.readthedocs.io/en/latest/\n",
    " * http://stephanhoyer.com/2015/06/11/xray-dask-out-of-core-labeled-arrays/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ÑπÔ∏è Info\n",
    "\n",
    "Jika ada pertanyaan atau komentar bisa mengirimkan email ke piksel@big.go.id\n",
    "\n",
    "**Lisensi:** Skrip dalam notebook ini dilisensikan berdasarkan [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Data Piksel dilisensikan berdasarkan lisensi [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(f\"Tanggal update: {datetime.now().strftime('%d %B %Y')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
